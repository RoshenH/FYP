{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d43b6f75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "\n",
      "=== Training Run 1/3 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Roshen Hasangha\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\optim\\lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 - Loss: 0.0255 - F1: 0.4615\n",
      "Model saved.\n",
      "Epoch 2 - Loss: 0.0245 - F1: 0.4162\n",
      "Epoch 3 - Loss: 0.0241 - F1: 0.4586\n",
      "Epoch 4 - Loss: 0.0226 - F1: 0.5255\n",
      "Model saved.\n",
      "Epoch 5 - Loss: 0.0215 - F1: 0.5180\n",
      "Epoch 6 - Loss: 0.0219 - F1: 0.5106\n",
      "Epoch 7 - Loss: 0.0225 - F1: 0.5180\n",
      "Epoch 8 - Loss: 0.0222 - F1: 0.5802\n",
      "Model saved.\n",
      "Epoch 9 - Loss: 0.0213 - F1: 0.5468\n",
      "Epoch 10 - Loss: 0.0217 - F1: 0.5170\n",
      "Epoch 11 - Loss: 0.0216 - F1: 0.5390\n",
      "Epoch 12 - Loss: 0.0204 - F1: 0.5170\n",
      "Epoch 13 - Loss: 0.0202 - F1: 0.4935\n",
      "Epoch 14 - Loss: 0.0210 - F1: 0.5736\n",
      "Epoch 15 - Loss: 0.0195 - F1: 0.5468\n",
      "Epoch 16 - Loss: 0.0200 - F1: 0.5166\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset, WeightedRandomSampler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import gc\n",
    "\n",
    "# Device setup\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Load and filter\n",
    "X_flux = np.load(\"X_flux_512.npy\")[..., np.newaxis]  # Shape: (829, 512, 1)\n",
    "X_tabular = np.load(\"X_tabular.npy\")\n",
    "y = np.load(\"y.npy\")\n",
    "mask = y != -1\n",
    "X_flux, X_tabular, y = X_flux[mask], X_tabular[mask], y[mask]\n",
    "\n",
    "# Train/Val split\n",
    "Xf_train, Xf_val, Xt_train, Xt_val, y_train, y_val = train_test_split(\n",
    "    X_flux, X_tabular, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "# Compute class weights for sampling\n",
    "class_sample_count = np.array([len(np.where(y_train == t)[0]) for t in np.unique(y_train)])\n",
    "weights = 1. / class_sample_count\n",
    "samples_weight = np.array([weights[int(t)] for t in y_train])\n",
    "samples_weight = torch.from_numpy(samples_weight).float()\n",
    "sampler = WeightedRandomSampler(samples_weight, len(samples_weight))\n",
    "\n",
    "# Tensor conversion\n",
    "Xf_train = Xf_train.transpose(0, 1, 2)  # From (663, 512, 1) to (663, 512, 1)\n",
    "Xf_val = Xf_val.transpose(0, 1, 2)      # From (166, 512, 1) to (166, 512, 1)\n",
    "\n",
    "train_dataset = TensorDataset(\n",
    "    torch.tensor(Xf_train, dtype=torch.float32),\n",
    "    torch.tensor(Xt_train, dtype=torch.float32),\n",
    "    torch.tensor(y_train, dtype=torch.float32).unsqueeze(1)\n",
    ")\n",
    "train_loader = DataLoader(train_dataset, batch_size=4, sampler=sampler, pin_memory=True)\n",
    "\n",
    "val_flux = torch.tensor(Xf_val, dtype=torch.float32)\n",
    "val_tab = torch.tensor(Xt_val, dtype=torch.float32)\n",
    "val_y = torch.tensor(y_val, dtype=torch.float32).unsqueeze(1)\n",
    "\n",
    "\n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, alpha=0.3, gamma=3.0):  \n",
    "        super().__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.bce = nn.BCEWithLogitsLoss(reduction='none')\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        bce_loss = self.bce(inputs, targets)\n",
    "        pt = torch.exp(-bce_loss)\n",
    "        focal_loss = self.alpha * (1 - pt) ** self.gamma * bce_loss\n",
    "        return focal_loss.mean()\n",
    "\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_len=2000):\n",
    "        super().__init__()\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2) * (-np.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        self.pe = pe.unsqueeze(0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x + self.pe[:, :x.size(1), :].to(x.device)\n",
    "\n",
    "\n",
    "class AdvancedMultimodalModel(nn.Module):\n",
    "    def __init__(self, seq_len=512, flux_dim=1, tabular_dim=5):\n",
    "        super().__init__()\n",
    "        self.input_proj = nn.Linear(flux_dim, 128)\n",
    "        self.pos_encoder = PositionalEncoding(128, seq_len)\n",
    "        self.transformer = nn.TransformerEncoder(\n",
    "            nn.TransformerEncoderLayer(d_model=128, nhead=8, batch_first=True),\n",
    "            num_layers=4\n",
    "        )\n",
    "        self.tabular_mlp = nn.Sequential(\n",
    "            nn.Linear(tabular_dim, 64),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(64, 128),\n",
    "            nn.GELU()\n",
    "        )\n",
    "        self.cross_attention = nn.MultiheadAttention(embed_dim=128, num_heads=4, batch_first=True)\n",
    "        self.gate = nn.Sequential(nn.Linear(128, 128), nn.Sigmoid())\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(128, 64),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(64, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, flux_x, tabular_x):\n",
    "        x = self.input_proj(flux_x)\n",
    "        x = self.pos_encoder(x)\n",
    "        x = self.transformer(x)\n",
    "        t = self.tabular_mlp(tabular_x).unsqueeze(1)\n",
    "        attn_output, _ = self.cross_attention(t, x, x)\n",
    "        fused = self.gate(attn_output) * attn_output + (1 - self.gate(attn_output)) * t\n",
    "        return self.classifier(fused.squeeze(1))\n",
    "\n",
    "\n",
    "def find_optimal_threshold(val_y, val_probs):\n",
    "    thresholds = np.linspace(0.1, 0.9, 81)\n",
    "    best_f1 = 0\n",
    "    best_threshold = 0.5\n",
    "    for thresh in thresholds:\n",
    "        preds = (val_probs > thresh).astype(int)\n",
    "        f1 = f1_score(val_y, preds)\n",
    "        if f1 > best_f1:\n",
    "            best_f1 = f1\n",
    "            best_threshold = thresh\n",
    "    return best_threshold, best_f1\n",
    "\n",
    "# Training \n",
    "num_runs = 3\n",
    "ensemble_probs = []\n",
    "ensemble_val_f1 = []\n",
    "best_thresholds = []\n",
    "\n",
    "for run in range(num_runs):\n",
    "    print(f\"\\n=== Training Run {run+1}/{num_runs} ===\")\n",
    "    torch.manual_seed(42 + run)\n",
    "\n",
    "\n",
    "    model = AdvancedMultimodalModel().to(device)\n",
    "    criterion = FocalLoss()\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4, weight_decay=1e-5)\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=5, verbose=True)\n",
    "\n",
    "  \n",
    "    train_loss_curve, val_f1_curve = [], []\n",
    "    best_f1, patience, counter = 0, 30, 0  # Increased patience\n",
    "    min_delta = 0.008\n",
    "\n",
    "    for epoch in range(30):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        for xb, xt, yb in train_loader:\n",
    "            xb, xt, yb = xb.to(device), xt.to(device), yb.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            out = model(xb, xt)\n",
    "            loss = criterion(out, yb)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "            del xb, xt, yb, out\n",
    "            gc.collect()\n",
    "\n",
    "        train_loss_curve.append(total_loss / len(train_loader))\n",
    "\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            val_out = model(val_flux.to(device), val_tab.to(device))\n",
    "            val_probs = torch.sigmoid(val_out).detach().cpu().numpy()\n",
    "            val_preds = (val_probs > 0.5).astype(int)\n",
    "            f1 = f1_score(val_y, val_preds)\n",
    "            val_f1_curve.append(f1)\n",
    "\n",
    "        print(f\"Epoch {epoch+1} - Loss: {train_loss_curve[-1]:.4f} - F1: {f1:.4f}\")\n",
    "        if f1 > best_f1 + min_delta:\n",
    "            best_f1 = f1\n",
    "            torch.save(model.state_dict(), f\"best_model_run{run}.pt\")\n",
    "            counter = 0\n",
    "            print(\"Model saved.\")\n",
    "        else:\n",
    "            counter += 1\n",
    "            if counter >= patience:\n",
    "                print(\"Early stopping.\")\n",
    "                break\n",
    "\n",
    "        # Adjust learning rate based on validation F1-score\n",
    "        scheduler.step(f1)\n",
    "\n",
    "   \n",
    "    model.load_state_dict(torch.load(f\"best_model_final{run}.pt\"))\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        val_out = model(val_flux.to(device), val_tab.to(device))\n",
    "        val_probs_run = torch.sigmoid(val_out).detach().cpu().numpy()\n",
    "        ensemble_probs.append(val_probs_run)\n",
    "\n",
    "   \n",
    "    thresh, f1 = find_optimal_threshold(val_y, val_probs_run)\n",
    "    best_thresholds.append(thresh)\n",
    "    ensemble_val_f1.append(f1)\n",
    "    print(f\"Run {run+1} - Best F1: {f1:.4f} at Threshold: {thresh:.2f}\")\n",
    "\n",
    "\n",
    "avg_probs = np.mean(ensemble_probs, axis=0)\n",
    "avg_threshold = np.mean(best_thresholds)\n",
    "final_preds = (avg_probs > avg_threshold).astype(int)\n",
    "\n",
    "print(\"\\nðŸ“Š Ensemble Validation Results:\")\n",
    "print(f\"Average Threshold: {avg_threshold:.2f}\")\n",
    "print(f\"Ensemble F1 Scores: {ensemble_val_f1}\")\n",
    "print(f\"Average F1 Score: {np.mean(ensemble_val_f1):.4f}\")\n",
    "print(\"\\nðŸ§¾ Classification Report:\")\n",
    "print(classification_report(val_y, final_preds, target_names=[\"False Positive\", \"Confirmed\"]))\n",
    "print(\"\\nðŸ§® Confusion Matrix:\")\n",
    "print(confusion_matrix(val_y, final_preds))\n",
    "\n",
    "# Plotting\n",
    "plt.plot(train_loss_curve, label=\"Loss\")\n",
    "plt.plot(val_f1_curve, label=\"F1 Score\")\n",
    "plt.title(\"Training Curve (Last Run)\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Value\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ab961c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "\n",
    "cm = confusion_matrix(val_y, final_preds)\n",
    "plt.figure(figsize=(5, 4))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=[\"False\", \"True\"], yticklabels=[\"False\", \"True\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71ce9f9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ”¸ Logistic Regression (Tabular Only)\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "False Positive       0.95      0.65      0.78       127\n",
      "     Confirmed       0.44      0.90      0.59        39\n",
      "\n",
      "      accuracy                           0.71       166\n",
      "     macro avg       0.70      0.78      0.68       166\n",
      "  weighted avg       0.83      0.71      0.73       166\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load and filter\n",
    "X_flux = np.load(\"X_flux_512.npy\")[..., np.newaxis]  # (samples, 512, 1)\n",
    "X_tabular = np.load(\"X_tabular.npy\")\n",
    "y = np.load(\"y.npy\")\n",
    "mask = y != -1\n",
    "X_flux, X_tabular, y = X_flux[mask], X_tabular[mask], y[mask]\n",
    "\n",
    "# Train/Val split for benchmarking models\n",
    "Xf_train, Xf_val, Xt_train, Xt_val, y_train, y_val = train_test_split(\n",
    "    X_flux, X_tabular, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "clf = LogisticRegression(class_weight='balanced', max_iter=1000)\n",
    "clf.fit(Xt_train, y_train)\n",
    "log_preds = clf.predict(Xt_val)\n",
    "\n",
    "print(\"\\nðŸ”¸ Logistic Regression (Tabular Only)\")\n",
    "print(classification_report(y_val, log_preds, target_names=[\"False Positive\", \"Confirmed\"]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6925c845",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ”¸ MLP (Tabular Only)\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "False Positive       0.77      1.00      0.87       127\n",
      "     Confirmed       0.00      0.00      0.00        39\n",
      "\n",
      "      accuracy                           0.77       166\n",
      "     macro avg       0.38      0.50      0.43       166\n",
      "  weighted avg       0.59      0.77      0.66       166\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Roshen Hasangha\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Roshen Hasangha\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Roshen Hasangha\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Ensure device is defined\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "class TabularMLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(5, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "tabular_model = TabularMLP().to(device)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(tabular_model.parameters(), lr=1e-3)\n",
    "\n",
    "Xtt_train = torch.tensor(Xt_train, dtype=torch.float32).to(device)\n",
    "ytt_train = torch.tensor(y_train, dtype=torch.float32).unsqueeze(1).to(device)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(30):\n",
    "    tabular_model.train()\n",
    "    optimizer.zero_grad()\n",
    "    output = tabular_model(Xtt_train)\n",
    "    loss = criterion(output, ytt_train)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "tabular_model.eval()\n",
    "with torch.no_grad():\n",
    "    val_logits = tabular_model(torch.tensor(Xt_val, dtype=torch.float32).to(device))\n",
    "    val_probs = torch.sigmoid(val_logits).cpu().numpy()\n",
    "    val_preds = (val_probs > 0.5).astype(int)\n",
    "\n",
    "print(\"\\nðŸ”¸ MLP (Tabular Only)\")\n",
    "print(classification_report(y_val, val_preds, target_names=[\"False Positive\", \"Confirmed\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0db7ff85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ”¸ 1D CNN (Flux Only)\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "False Positive       0.77      1.00      0.87       127\n",
      "     Confirmed       0.00      0.00      0.00        39\n",
      "\n",
      "      accuracy                           0.77       166\n",
      "     macro avg       0.38      0.50      0.43       166\n",
      "  weighted avg       0.59      0.77      0.66       166\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Roshen Hasangha\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Roshen Hasangha\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Roshen Hasangha\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "class FluxCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.cnn = nn.Sequential(\n",
    "            nn.Conv1d(1, 32, kernel_size=5, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(2),\n",
    "            nn.Conv1d(32, 64, kernel_size=5, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.AdaptiveAvgPool1d(1),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(64, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.cnn(x)\n",
    "\n",
    "flux_model = FluxCNN().to(device)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(flux_model.parameters(), lr=1e-3)\n",
    "\n",
    "Xff_train = torch.tensor(Xf_train, dtype=torch.float32).permute(0, 2, 1).to(device)\n",
    "yff_train = torch.tensor(y_train, dtype=torch.float32).unsqueeze(1).to(device)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(30):\n",
    "    flux_model.train()\n",
    "    optimizer.zero_grad()\n",
    "    output = flux_model(Xff_train)\n",
    "    loss = criterion(output, yff_train)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "flux_model.eval()\n",
    "with torch.no_grad():\n",
    "    val_flux_tensor = torch.tensor(Xf_val, dtype=torch.float32).permute(0, 2, 1).to(device)\n",
    "    val_logits = flux_model(val_flux_tensor)\n",
    "    val_probs = torch.sigmoid(val_logits).cpu().numpy()\n",
    "    val_preds = (val_probs > 0.5).astype(int)\n",
    "\n",
    "print(\"\\nðŸ”¸ 1D CNN (Flux Only)\")\n",
    "print(classification_report(y_val, val_preds, target_names=[\"False Positive\", \"Confirmed\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b792d78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ”¸ Early Fusion MLP (Flux Mean + Tabular)\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "False Positive       0.77      1.00      0.87       127\n",
      "     Confirmed       0.00      0.00      0.00        39\n",
      "\n",
      "      accuracy                           0.77       166\n",
      "     macro avg       0.38      0.50      0.43       166\n",
      "  weighted avg       0.59      0.77      0.66       166\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Roshen Hasangha\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Roshen Hasangha\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Roshen Hasangha\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "X_flux_mean_train = Xf_train.mean(axis=1)\n",
    "X_flux_mean_val = Xf_val.mean(axis=1)\n",
    "\n",
    "X_early_train = np.concatenate([X_flux_mean_train, Xt_train], axis=1)\n",
    "X_early_val = np.concatenate([X_flux_mean_val, Xt_val], axis=1)\n",
    "\n",
    "class EarlyFusionMLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(6, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "fusion_model = EarlyFusionMLP().to(device)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(fusion_model.parameters(), lr=1e-3)\n",
    "\n",
    "Xef_train = torch.tensor(X_early_train, dtype=torch.float32).to(device)\n",
    "yef_train = torch.tensor(y_train, dtype=torch.float32).unsqueeze(1).to(device)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(30):\n",
    "    fusion_model.train()\n",
    "    optimizer.zero_grad()\n",
    "    output = fusion_model(Xef_train)\n",
    "    loss = criterion(output, yef_train)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "fusion_model.eval()\n",
    "with torch.no_grad():\n",
    "    val_logits = fusion_model(torch.tensor(X_early_val, dtype=torch.float32).to(device))\n",
    "    val_probs = torch.sigmoid(val_logits).cpu().numpy()\n",
    "    val_preds = (val_probs > 0.5).astype(int)\n",
    "\n",
    "print(\"\\nðŸ”¸ Early Fusion MLP (Flux Mean + Tabular)\")\n",
    "print(classification_report(y_val, val_preds, target_names=[\"False Positive\", \"Confirmed\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b36fcf56",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
